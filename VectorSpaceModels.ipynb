{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VectorSpaceModels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1u4uRLPSjX5lZKcq6Cnvbgvdrnm1Gw3wP",
      "authorship_tag": "ABX9TyNTUzjMkrJXQyelt2ijaDP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiuliaLanzillotta/NLU/blob/master/VectorSpaceModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC8s_j0lqi42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.spatial.distance as distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoFwVg1WoPRf",
        "colab_type": "text"
      },
      "source": [
        "# Getting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qRHi8SC9V2F",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_GO7i-InYoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls 'drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u202L-3cn43w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "17e82c10-4330-4cd7-d6d9-415476c91bcc"
      },
      "source": [
        "!wget http://web.stanford.edu/class/cs224u/data/data.tgz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 16:14:55--  http://web.stanford.edu/class/cs224u/data/data.tgz\n",
            "Resolving web.stanford.edu (web.stanford.edu)... 171.67.215.200\n",
            "Connecting to web.stanford.edu (web.stanford.edu)|171.67.215.200|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1531647000 (1.4G) [application/x-gzip]\n",
            "Saving to: ‘data.tgz’\n",
            "\n",
            "data.tgz            100%[===================>]   1.43G  7.96MB/s    in 3m 13s  \n",
            "\n",
            "2020-03-06 16:18:09 (7.57 MB/s) - ‘data.tgz’ saved [1531647000/1531647000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J0D9PpupBuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xvzf data.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tC1INPpoNQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp './data/' 'drive/My Drive' -r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU0ClIXMpSz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_HOME = 'drive/My Drive/data/vsmdata'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOycmkohp-iL",
        "colab_type": "text"
      },
      "source": [
        "# Build the vocabulary \n",
        "using a co-occurrence matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2jq1i_qBFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBexG2tXqU_y",
        "colab_type": "text"
      },
      "source": [
        "# Analysing pre-computed matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AYDpBfsq7gK",
        "colab_type": "text"
      },
      "source": [
        "Syntactic information\n",
        "- Source : IMDB movie reviews\n",
        "- Window size: 5 \n",
        "- Weighting: 1/distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlYVyIQXqe92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb5 = pd.read_csv(\n",
        "    os.path.join(DATA_HOME, 'imdb_window5-scaled.csv.gz'), index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6QHpifNrORV",
        "colab_type": "text"
      },
      "source": [
        "Semantica information\n",
        "- Source : IMDB movie reviews\n",
        "- Window size: 20\n",
        "- Weighting: 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCeC0qLSqhzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb20 = pd.read_csv(\n",
        "    os.path.join(DATA_HOME, 'imdb_window20-flat.csv.gz'), index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXuys_8wrr18",
        "colab_type": "text"
      },
      "source": [
        "## But what is our goal? \n",
        "> *Ideally* we would like to represent **semantically related words close together** in the vector space, <br>\n",
        "and semantically unrelated words should end up far apart\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF_TzGbz2HMx",
        "colab_type": "text"
      },
      "source": [
        "## Distance metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcmyirFSsrFS",
        "colab_type": "text"
      },
      "source": [
        "The definition of distance in the VSM is therefore essential. <br>\n",
        "I will now explore different distance definitions on the pre-computed matrices.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Note: <br>most of the distance metrics presented here do not qualifyeffectively as distance metrics, mainly because they don't satisfy the triangle inequality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNuRW_KEsjYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's select 3 words \n",
        "# imdb 5\n",
        "zombie5 = imdb5.loc[\"zombie\"].array\n",
        "death5 = imdb5.loc[\"death\"].array\n",
        "happy5 = imdb5.loc[\"happy\"].array\n",
        "# imbd 20\n",
        "zombie20 = imdb20.loc[\"zombie\"].array\n",
        "death20 = imdb20.loc[\"death\"].array\n",
        "happy20 = imdb20.loc[\"happy\"].array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR3yGLwntpw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93357258-84a9-41a7-9b88-364fe1a81ce6"
      },
      "source": [
        "words5 = np.array([zombie5,death5,happy5])\n",
        "words5.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5hwo1zWwSnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8997f9cc-127c-457c-b380-03f98a3be894"
      },
      "source": [
        "words20 = np.array([zombie20,death20,happy20])\n",
        "words20.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoZvOO1FuC7p",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nTAXM00t7wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = distance.euclidean(zombie5,death5)\n",
        "d2 = distance.euclidean(zombie5,happy5)\n",
        "d3 = distance.euclidean(death5,happy5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh0-wyTZupjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f1ba2d62-3182-4aa1-8e62-c0ba992851ad"
      },
      "source": [
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  140678.50846327867\n",
            "Zombie-happy:  79913.87661592668\n",
            "Happy-death:  153085.63009060753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6exnSu7Luzmq",
        "colab_type": "text"
      },
      "source": [
        "This apparently weird result has a simple explanation: using the Euclidean distance we are taking into account the absolute number of occurrences of the words. Hence, words that are both frequent will appear more similar to each other than words that have different frequencies. We can assume that the word *Zombie* is not frequent in movies' reviews as the words *happy* and *death*, which is why *happy* and *death* are closer together then *zombie* and *death*.\n",
        "<br>\n",
        "<br>\n",
        "Let's now look at the same analysis on the flatter dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ynxOoduvVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = distance.euclidean(zombie20,death20)\n",
        "d2 = distance.euclidean(zombie20,happy20)\n",
        "d3 = distance.euclidean(death20,happy20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC084CLjwcQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f81f137f-1d8e-4638-8898-6d8770a1cc29"
      },
      "source": [
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  222839.7455190613\n",
            "Zombie-happy:  112295.34699176098\n",
            "Happy-death:  190959.80210766871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyeWmQeJwqm5",
        "colab_type": "text"
      },
      "source": [
        "As we can see, taking into account a larger co-occurrence window and using a flat weighting scheme decreases the effect of frequency on similarity, thus enhancing the semantic meaning of a word.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW1caBlAxaxa",
        "colab_type": "text"
      },
      "source": [
        "### Normalised Euclidean Distance or Cosine-distance\n",
        "Normalising the length results in not taking into account the absolute value of frequencies of the words when computing the similarity. This should bring even more far apart the words that have different meanings. \n",
        "<br>\n",
        "<br>\n",
        "Euclidean with L2-normed vectors is equivalent to cosine\n",
        "w.r.t. ranking.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-e1cDw9wdqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "093a4056-6e5e-40d0-a943-20c9bad4cbb5"
      },
      "source": [
        "d1 = distance.cosine(zombie5,death5)\n",
        "d2 = distance.cosine(zombie5,happy5)\n",
        "d3 = distance.cosine(death5,happy5)\n",
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  0.9821138850310313\n",
            "Zombie-happy:  0.9819876080334038\n",
            "Happy-death:  0.9797060511902813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGJSCZQ0yVsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "45b718d2-1355-4141-af5e-4970697faf90"
      },
      "source": [
        "d1 = distance.cosine(zombie20,death20)\n",
        "d2 = distance.cosine(zombie20,happy20)\n",
        "d3 = distance.cosine(death20,happy20)\n",
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  0.33280097194242764\n",
            "Zombie-happy:  0.3116146909460501\n",
            "Happy-death:  0.28845341896736065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqGLL2HwzWKp",
        "colab_type": "text"
      },
      "source": [
        "One major difference that we can observe between this last result and the result obtained by using the Euclidean distance is that the similarity between *Happy* and *Death* is now ranked last (in both datasets), even though the two words appear with the same order of frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53HaCbon0gj0",
        "colab_type": "text"
      },
      "source": [
        "### Matching based distances: Jaccard distance\n",
        "Here we explore matching as a method to compute distances between words. Since the matching coefficient depends heavily on the raw frequencies of the words it could be necessary to apply a *standardization* on the coefficient, like it's done in the *Jaccard distance* case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwBB5oqyzKXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ba484440-854a-418c-da05-484ec0bf4ed9"
      },
      "source": [
        "d1 = distance.jaccard(zombie5,death5)\n",
        "d2 = distance.jaccard(zombie5,happy5)\n",
        "d3 = distance.jaccard(death5,happy5)\n",
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  0.9961356805495921\n",
            "Zombie-happy:  0.9897213339424394\n",
            "Happy-death:  0.9953241232731137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNt9J2bQ1jdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4e472f11-436d-4b69-9252-721e2302b729"
      },
      "source": [
        "d1 = distance.jaccard(zombie20,death20)\n",
        "d2 = distance.jaccard(zombie20,happy20)\n",
        "d3 = distance.jaccard(death20,happy20)\n",
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  0.9937055837563452\n",
            "Zombie-happy:  0.9768881551795295\n",
            "Happy-death:  0.9846371538306045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWzzQTLU2R2u",
        "colab_type": "text"
      },
      "source": [
        "### Probability-based norms\n",
        "\n",
        "Probability-based norms compute a probability distribution for each word (hence associating a probability mass to each other word in the vocabulary based on the co-occurrence factor) and then compute the distance between two words in the probability metrics space.\n",
        "<br>\n",
        "<br>\n",
        "An example of symmetric probability-based norm is the *Jensen-Shannon* divergence, which is based on the *KL-divergence*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oghvE59c1oNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First we normalise the arrays\n",
        "zombie5n = zombie5/np.sum(zombie5)\n",
        "death5n = death5/np.sum(death5)\n",
        "happy5n = happy5/np.sum(happy5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3dFTH0c5R6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "acda02cb-917f-4565-e4d6-22e823a95e94"
      },
      "source": [
        "d1 = distance.jensenshannon(zombie5n,death5n)\n",
        "d2 = distance.jensenshannon(zombie5n,happy5n)\n",
        "d3 = distance.jensenshannon(death5n,happy5n)\n",
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  0.6471835294189927\n",
            "Zombie-happy:  0.6472151522431021\n",
            "Happy-death:  0.6472732505531924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zmJgfQ6MIY",
        "colab_type": "text"
      },
      "source": [
        "*happy-death* > *zombie-happy* > *zombie-death*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaWHs1EU4gDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First we normalise the arrays\n",
        "zombie20n = zombie20/np.sum(zombie20)\n",
        "death20n = death20/np.sum(death20)\n",
        "happy20n = happy20/np.sum(happy20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c27-rBli5el8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a4d54fc5-acc2-4678-b0a7-8bcd3af5fc2a"
      },
      "source": [
        "d1 = distance.jensenshannon(zombie20n,death20n)\n",
        "d2 = distance.jensenshannon(zombie20n,happy20n)\n",
        "d3 = distance.jensenshannon(death20n,happy20n)\n",
        "print(\"Zombie-death: \",d1)\n",
        "print(\"Zombie-happy: \",d2)\n",
        "print(\"Happy-death: \",d3)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zombie-death:  0.3148975947848389\n",
            "Zombie-happy:  0.31499963283886195\n",
            "Happy-death:  0.27413988112993093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhhzFQ3X6dFY",
        "colab_type": "text"
      },
      "source": [
        "*zombie-happy* > *zombie-death* > *happy-death*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr4EZBvu6_ef",
        "colab_type": "text"
      },
      "source": [
        "It may be interesting to notice from this result that the words happy and death appear more similar in distribution when using a larger window to scan the text. \n",
        "<br>\n",
        "Also, differently from the Jaccard distance result, the definition of the window and the weighting scheme has an effect on ranking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAjYhZob1131",
        "colab_type": "text"
      },
      "source": [
        "Note: \n",
        "> Both L2-norms and probability distributions can obscure\n",
        "differences in the amount/strength of evidence, which\n",
        "can in turn have an effect on the reliability of cosine,\n",
        "normed-euclidean, and KL divergence. These\n",
        "shortcomings might be addressed through weighting\n",
        "schemes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dre-GG1v1-fU",
        "colab_type": "text"
      },
      "source": [
        "## Re-weighting schemes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkd8foJr16aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}